{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with ModernBERT & GLUE\n",
    "\n",
    "Created by: [Wayde Gilliam](https://twitter.com/waydegilliam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders Strike Back!\n",
    "\n",
    "Like many, I have fond memories of finetuning deberta, roberta and bert models for a number of Kaggle comps and real-world problems (e.g., NER, sentiment analysis, etc.).  Encoder models were \"the thing\" back in the day and continue to be the primary workhorse for many ML pipelines today though they have been eclipsed by recent advancements in LLMs which typically are based on decoder-only architectures. Long have we awaited a return to an encoder model for the modern world. With ModernBERT, that wait is over! ModernBERT is a new encoder-only model that incorporates the latest features in making neural networks more efficient, faster, and better at handling tasks that encoder models have long excelled at such at text classification.  In addition, ModernBERT allows us to break out of that max 512 token limit with their long context capabilities which give us 8,192 tokens to play with.\n",
    "\n",
    "In this tutorial, we'll go through the steps of fine-tuning ModernBERT for one of the GLUE tasks, MRPC.  We'll cover some key settings required to use it with the HuggingFace trainer and include with some recommended hyperparameters that have served us well in fine-tuning ModernBERT for GLUE.  We'll also see how to use the model for inference and cleanup the model from the GPU to free up resources.\n",
    "\n",
    "As an aside, I'm running all this code on a single 3090 with plenty of GPU memory to spare.\n",
    "\n",
    "Though not strictly necessary, **ModernBERT trains better with FlashAttention!**. Training and inference will be much faster with it installed. See below:\n",
    "\n",
    "ModernBERT is built on top of FlashAttention which is a highly optimized implementation of the attention mechanism that is faster and more memory efficient than the standard implementation.  ***The beauty of this is all you need to do is install it for ModernBERT to work with it!***  Here's how ...\n",
    "\n",
    "For NVIDIA GPUs with compute capability 8.0+ (Ampere/Ada/Hopper architecture - A100, A6000, RTX 3090, RTX 4090, H100 etc):\n",
    "```python\n",
    "pip install flash-attn --no-build-isolation\n",
    "```\n",
    "\n",
    "For older NVIDIA GPUs (pre-Ampere):\n",
    "```python\n",
    "pip install flash-attn --no-deps\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install transformers datasets accelerate scikit-learn -Uqq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/mambaforge/envs/hf_tutorials/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from functools import partial\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, f1_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is GLUE?\n",
    "\n",
    "The [General Language Understanding Evaluation (GLUE) benchmark](https://gluebenchmark.com/) is a collection of nine diverse natural language understanding tasks designed to evaluate and compare the performance of NLP models across various language comprehension challenges. By providing a standardized framework, GLUE facilitates the development of models that generalize well across multiple tasks, promoting advancements in creating robust and versatile language understanding systems. \n",
    "\n",
    "Let's put this all these tasks in a dictionary along with some other helpful metadata about each one that might prove useful to iteratting over all of them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c44bc_row0_col0, #T_c44bc_row0_col1, #T_c44bc_row0_col2, #T_c44bc_row0_col3, #T_c44bc_row0_col4, #T_c44bc_row0_col5, #T_c44bc_row1_col0, #T_c44bc_row1_col1, #T_c44bc_row1_col2, #T_c44bc_row1_col3, #T_c44bc_row1_col4, #T_c44bc_row1_col5, #T_c44bc_row2_col0, #T_c44bc_row2_col1, #T_c44bc_row2_col2, #T_c44bc_row2_col3, #T_c44bc_row2_col4, #T_c44bc_row2_col5, #T_c44bc_row3_col0, #T_c44bc_row3_col1, #T_c44bc_row3_col2, #T_c44bc_row3_col3, #T_c44bc_row3_col4, #T_c44bc_row3_col5, #T_c44bc_row4_col0, #T_c44bc_row4_col1, #T_c44bc_row4_col2, #T_c44bc_row4_col3, #T_c44bc_row4_col4, #T_c44bc_row4_col5, #T_c44bc_row5_col0, #T_c44bc_row5_col1, #T_c44bc_row5_col2, #T_c44bc_row5_col3, #T_c44bc_row5_col4, #T_c44bc_row5_col5, #T_c44bc_row6_col0, #T_c44bc_row6_col1, #T_c44bc_row6_col2, #T_c44bc_row6_col3, #T_c44bc_row6_col4, #T_c44bc_row6_col5, #T_c44bc_row7_col0, #T_c44bc_row7_col1, #T_c44bc_row7_col2, #T_c44bc_row7_col3, #T_c44bc_row7_col4, #T_c44bc_row7_col5, #T_c44bc_row8_col0, #T_c44bc_row8_col1, #T_c44bc_row8_col2, #T_c44bc_row8_col3, #T_c44bc_row8_col4, #T_c44bc_row8_col5, #T_c44bc_row9_col0, #T_c44bc_row9_col1, #T_c44bc_row9_col2, #T_c44bc_row9_col3, #T_c44bc_row9_col4, #T_c44bc_row9_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c44bc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c44bc_level0_col0\" class=\"col_heading level0 col0\" >Abbr</th>\n",
       "      <th id=\"T_c44bc_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_c44bc_level0_col2\" class=\"col_heading level0 col2\" >Task type</th>\n",
       "      <th id=\"T_c44bc_level0_col3\" class=\"col_heading level0 col3\" >Description</th>\n",
       "      <th id=\"T_c44bc_level0_col4\" class=\"col_heading level0 col4\" >Size</th>\n",
       "      <th id=\"T_c44bc_level0_col5\" class=\"col_heading level0 col5\" >Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c44bc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c44bc_row0_col0\" class=\"data row0 col0\" >CoLA</td>\n",
       "      <td id=\"T_c44bc_row0_col1\" class=\"data row0 col1\" >Corpus of Linguistic Acceptability</td>\n",
       "      <td id=\"T_c44bc_row0_col2\" class=\"data row0 col2\" >Single-Sentence Task</td>\n",
       "      <td id=\"T_c44bc_row0_col3\" class=\"data row0 col3\" >Predict whether a sequence is a grammatical English sentence</td>\n",
       "      <td id=\"T_c44bc_row0_col4\" class=\"data row0 col4\" >8.5k</td>\n",
       "      <td id=\"T_c44bc_row0_col5\" class=\"data row0 col5\" >Matthews corr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c44bc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c44bc_row1_col0\" class=\"data row1 col0\" >SST-2</td>\n",
       "      <td id=\"T_c44bc_row1_col1\" class=\"data row1 col1\" >Stanford Sentiment Treebank</td>\n",
       "      <td id=\"T_c44bc_row1_col2\" class=\"data row1 col2\" >Single-Sentence Task</td>\n",
       "      <td id=\"T_c44bc_row1_col3\" class=\"data row1 col3\" >Predict the sentiment of a given sentence</td>\n",
       "      <td id=\"T_c44bc_row1_col4\" class=\"data row1 col4\" >67k</td>\n",
       "      <td id=\"T_c44bc_row1_col5\" class=\"data row1 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c44bc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c44bc_row2_col0\" class=\"data row2 col0\" >MRPC</td>\n",
       "      <td id=\"T_c44bc_row2_col1\" class=\"data row2 col1\" >Microsoft Research Paraphrase Corpus</td>\n",
       "      <td id=\"T_c44bc_row2_col2\" class=\"data row2 col2\" >Similarity and Paraphrase Tasks</td>\n",
       "      <td id=\"T_c44bc_row2_col3\" class=\"data row2 col3\" >Predict whether two sentences are semantically equivalent</td>\n",
       "      <td id=\"T_c44bc_row2_col4\" class=\"data row2 col4\" >3.7k</td>\n",
       "      <td id=\"T_c44bc_row2_col5\" class=\"data row2 col5\" >F1/Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c44bc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c44bc_row3_col0\" class=\"data row3 col0\" >SST-B</td>\n",
       "      <td id=\"T_c44bc_row3_col1\" class=\"data row3 col1\" >Semantic Textual Similarity Benchmark</td>\n",
       "      <td id=\"T_c44bc_row3_col2\" class=\"data row3 col2\" >Similarity and Paraphrase Tasks</td>\n",
       "      <td id=\"T_c44bc_row3_col3\" class=\"data row3 col3\" >Predict the similarity score for two sentences on a scale from 1 to 5</td>\n",
       "      <td id=\"T_c44bc_row3_col4\" class=\"data row3 col4\" >7k</td>\n",
       "      <td id=\"T_c44bc_row3_col5\" class=\"data row3 col5\" >Pearson/Spearman corr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c44bc_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c44bc_row4_col0\" class=\"data row4 col0\" >QQP</td>\n",
       "      <td id=\"T_c44bc_row4_col1\" class=\"data row4 col1\" >Quora question pair</td>\n",
       "      <td id=\"T_c44bc_row4_col2\" class=\"data row4 col2\" >Similarity and Paraphrase Tasks</td>\n",
       "      <td id=\"T_c44bc_row4_col3\" class=\"data row4 col3\" >Predict if two questions are a paraphrase of one another</td>\n",
       "      <td id=\"T_c44bc_row4_col4\" class=\"data row4 col4\" >364k</td>\n",
       "      <td id=\"T_c44bc_row4_col5\" class=\"data row4 col5\" >F1/Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c44bc_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c44bc_row5_col0\" class=\"data row5 col0\" >MNLI</td>\n",
       "      <td id=\"T_c44bc_row5_col1\" class=\"data row5 col1\" >Mulit-Genre Natural Language Inference</td>\n",
       "      <td id=\"T_c44bc_row5_col2\" class=\"data row5 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_c44bc_row5_col3\" class=\"data row5 col3\" >Predict whether the premise entails, contradicts or is neutral to the hypothesis</td>\n",
       "      <td id=\"T_c44bc_row5_col4\" class=\"data row5 col4\" >393k</td>\n",
       "      <td id=\"T_c44bc_row5_col5\" class=\"data row5 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c44bc_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c44bc_row6_col0\" class=\"data row6 col0\" >MNLI</td>\n",
       "      <td id=\"T_c44bc_row6_col1\" class=\"data row6 col1\" >Mulit-Genre Natural Language Inference</td>\n",
       "      <td id=\"T_c44bc_row6_col2\" class=\"data row6 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_c44bc_row6_col3\" class=\"data row6 col3\" >Predict whether the premise entails, contradicts or is neutral to the hypothesis</td>\n",
       "      <td id=\"T_c44bc_row6_col4\" class=\"data row6 col4\" >393k</td>\n",
       "      <td id=\"T_c44bc_row6_col5\" class=\"data row6 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c44bc_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c44bc_row7_col0\" class=\"data row7 col0\" >QNLI</td>\n",
       "      <td id=\"T_c44bc_row7_col1\" class=\"data row7 col1\" >Stanford Question Answering Dataset</td>\n",
       "      <td id=\"T_c44bc_row7_col2\" class=\"data row7 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_c44bc_row7_col3\" class=\"data row7 col3\" >Predict whether the context sentence contains the answer to the question</td>\n",
       "      <td id=\"T_c44bc_row7_col4\" class=\"data row7 col4\" >105k</td>\n",
       "      <td id=\"T_c44bc_row7_col5\" class=\"data row7 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c44bc_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c44bc_row8_col0\" class=\"data row8 col0\" >RTE</td>\n",
       "      <td id=\"T_c44bc_row8_col1\" class=\"data row8 col1\" >Recognize Textual Entailment</td>\n",
       "      <td id=\"T_c44bc_row8_col2\" class=\"data row8 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_c44bc_row8_col3\" class=\"data row8 col3\" >Predict whether one sentece entails another</td>\n",
       "      <td id=\"T_c44bc_row8_col4\" class=\"data row8 col4\" >2.5k</td>\n",
       "      <td id=\"T_c44bc_row8_col5\" class=\"data row8 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c44bc_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c44bc_row9_col0\" class=\"data row9 col0\" >WNLI</td>\n",
       "      <td id=\"T_c44bc_row9_col1\" class=\"data row9 col1\" >Winograd Schema Challenge</td>\n",
       "      <td id=\"T_c44bc_row9_col2\" class=\"data row9 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_c44bc_row9_col3\" class=\"data row9 col3\" >Predict if the sentence with the pronoun substituted is entailed by the original sentence</td>\n",
       "      <td id=\"T_c44bc_row9_col4\" class=\"data row9 col4\" >634</td>\n",
       "      <td id=\"T_c44bc_row9_col5\" class=\"data row9 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7fdb367fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glue_tasks = {\n",
    "    \"cola\": {\n",
    "        \"abbr\": \"CoLA\",\n",
    "        \"name\": \"Corpus of Linguistic Acceptability\",\n",
    "        \"description\": \"Predict whether a sequence is a grammatical English sentence\",\n",
    "        \"task_type\": \"Single-Sentence Task\",\n",
    "        \"domain\": \"Misc.\",\n",
    "        \"size\": \"8.5k\",\n",
    "        \"metrics\": \"Matthews corr.\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [matthews_corrcoef],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"sst2\": {\n",
    "        \"abbr\": \"SST-2\",\n",
    "        \"name\": \"Stanford Sentiment Treebank\",\n",
    "        \"description\": \"Predict the sentiment of a given sentence\",\n",
    "        \"task_type\": \"Single-Sentence Task\",\n",
    "        \"domain\": \"Movie reviews\",\n",
    "        \"size\": \"67k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"mrpc\": {\n",
    "        \"abbr\": \"MRPC\",\n",
    "        \"name\": \"Microsoft Research Paraphrase Corpus\",\n",
    "        \"description\": \"Predict whether two sentences are semantically equivalent\",\n",
    "        \"task_type\": \"Similarity and Paraphrase Tasks\",\n",
    "        \"domain\": \"News\",\n",
    "        \"size\": \"3.7k\",\n",
    "        \"metrics\": \"F1/Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence1\", \"sentence2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score, f1_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"stsb\": {\n",
    "        \"abbr\": \"SST-B\",\n",
    "        \"name\": \"Semantic Textual Similarity Benchmark\",\n",
    "        \"description\": \"Predict the similarity score for two sentences on a scale from 1 to 5\",\n",
    "        \"task_type\": \"Similarity and Paraphrase Tasks\",\n",
    "        \"domain\": \"Misc.\",\n",
    "        \"size\": \"7k\",\n",
    "        \"metrics\": \"Pearson/Spearman corr.\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence1\", \"sentence2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [pearsonr, spearmanr],\n",
    "        \"n_labels\": 1,\n",
    "    },\n",
    "    \"qqp\": {\n",
    "        \"abbr\": \"QQP\",\n",
    "        \"name\": \"Quora question pair\",\n",
    "        \"description\": \"Predict if two questions are a paraphrase of one another\",\n",
    "        \"task_type\": \"Similarity and Paraphrase Tasks\",\n",
    "        \"domain\": \"Social QA questions\",\n",
    "        \"size\": \"364k\",\n",
    "        \"metrics\": \"F1/Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"question1\", \"question2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [f1_score, accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"mnli-matched\": {\n",
    "        \"abbr\": \"MNLI\",\n",
    "        \"name\": \"Mulit-Genre Natural Language Inference\",\n",
    "        \"description\": \"Predict whether the premise entails, contradicts or is neutral to the hypothesis\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Misc.\",\n",
    "        \"size\": \"393k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation_matched\", \"test\": \"test_matched\"},\n",
    "        \"inputs\": [\"premise\", \"hypothesis\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 3,\n",
    "    },\n",
    "    \"mnli-mismatched\": {\n",
    "        \"abbr\": \"MNLI\",\n",
    "        \"name\": \"Mulit-Genre Natural Language Inference\",\n",
    "        \"description\": \"Predict whether the premise entails, contradicts or is neutral to the hypothesis\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Misc.\",\n",
    "        \"size\": \"393k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation_mismatched\", \"test\": \"test_mismatched\"},\n",
    "        \"inputs\": [\"premise\", \"hypothesis\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 3,\n",
    "    },\n",
    "    \"qnli\": {\n",
    "        \"abbr\": \"QNLI\",\n",
    "        \"name\": \"Stanford Question Answering Dataset\",\n",
    "        \"description\": \"Predict whether the context sentence contains the answer to the question\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Wikipedia\",\n",
    "        \"size\": \"105k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"question\", \"sentence\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"rte\": {\n",
    "        \"abbr\": \"RTE\",\n",
    "        \"name\": \"Recognize Textual Entailment\",\n",
    "        \"description\": \"Predict whether one sentence entails another\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"News, Wikipedia\",\n",
    "        \"size\": \"2.5k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence1\", \"sentence2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"wnli\": {\n",
    "        \"abbr\": \"WNLI\",\n",
    "        \"name\": \"Winograd Schema Challenge\",\n",
    "        \"description\": \"Predict if the sentence with the pronoun substituted is entailed by the original sentence\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Fiction books\",\n",
    "        \"size\": \"634\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence1\", \"sentence2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "}\n",
    "\n",
    "# for v in glue_tasks.values(): print(v)\n",
    "glue_tasks.values()\n",
    "\n",
    "glue_df = pd.DataFrame(glue_tasks.values(), columns=[\"abbr\", \"name\", \"task_type\", \"description\", \"size\", \"metrics\"])\n",
    "glue_df.columns = glue_df.columns.str.replace(\"_\", \" \").str.capitalize()\n",
    "display(glue_df.style.set_properties(**{\"text-align\": \"left\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Fine-Tune ModernBERT for MRPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "ModernBERT currently comes in two flavors, base and large. To keep things lean and mean, we'll use the \"answerdotai/ModernBERT-base\" checkpoint for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"mrpc\"\n",
    "task_meta = glue_tasks[task]\n",
    "train_ds_name = task_meta[\"dataset_names\"][\"train\"]\n",
    "valid_ds_name = task_meta[\"dataset_names\"][\"valid\"]\n",
    "test_ds_name = task_meta[\"dataset_names\"][\"test\"]\n",
    "\n",
    "task_inputs = task_meta[\"inputs\"]\n",
    "task_target = task_meta[\"target\"]\n",
    "n_labels = task_meta[\"n_labels\"]\n",
    "task_metrics = task_meta[\"metric_funcs\"]\n",
    "\n",
    "checkpoint = \"answerdotai/ModernBERT-base\"  # \"answerdotai/ModernBERT-base\", \"answerdotai/ModernBERT-large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `Datasets` library to load the data.  As its always recommended to \"look at your data\" before we get training, we'll also print out a single example to see what we're working with as well as the features of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n",
      "\n",
      "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0}\n",
      "\n",
      "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", task)\n",
    "\n",
    "print(f\"{raw_datasets}\\n\")\n",
    "print(f\"{raw_datasets[train_ds_name][0]}\\n\")\n",
    "print(f\"{raw_datasets[train_ds_name].features}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following dictionaries when building our model with `AutoModelForSequenceClassification` to map between the label ids and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_maps(raw_datasets, train_ds_name):\n",
    "    labels = raw_datasets[train_ds_name].features[\"label\"]\n",
    "\n",
    "    id2label = {idx: name.upper() for idx, name in enumerate(labels.names)} if hasattr(labels, \"names\") else None\n",
    "    label2id = {name.upper(): idx for idx, name in enumerate(labels.names)} if hasattr(labels, \"names\") else None\n",
    "\n",
    "    return id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'NOT_EQUIVALENT', 1: 'EQUIVALENT'}\n",
      "{'NOT_EQUIVALENT': 0, 'EQUIVALENT': 1}\n"
     ]
    }
   ],
   "source": [
    "id2label, label2id = get_label_maps(raw_datasets, train_ds_name)\n",
    "\n",
    "print(f\"{id2label}\")\n",
    "print(f\"{label2id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRPC is a sentence-pair classification task where we're given two sentences and asked to predict whether they are paraphrases of one another.  The dataset is split into train, validation and test sets. We'll need to keep all this in mind when we set up tokenization next with `AutoTokenizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "Next we define our Tokenizer and a preprocess function to create the input_ids, attention_mask, and token_type_ids the model needs to train.  For this example, including `truncation=True` is enough as we'll rely on our data collation function below to put our batches into the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence1', 'sentence2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, task_inputs):\n",
    "    inps = [examples[inp] for inp in task_inputs]\n",
    "    tokenized = hf_tokenizer(*inps, truncation=True)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n",
      "\n",
      "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0, 'input_ids': [50281, 8096, 287, 9877, 10145, 521, 4929, 1157, 5207, 344, 1925, 346, 253, 5517, 346, 1157, 273, 21547, 940, 12655, 521, 1941, 964, 50282, 7676, 24247, 281, 779, 347, 760, 346, 253, 5517, 346, 1157, 3052, 287, 9877, 10145, 521, 4929, 273, 21547, 940, 12655, 521, 1941, 964, 50282], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "\n",
      "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(partial(preprocess_function, task_inputs=task_inputs), batched=True)\n",
    "\n",
    "print(f\"{tokenized_datasets}\\n\")\n",
    "print(f\"{tokenized_datasets[train_ds_name][0]}\\n\")\n",
    "print(f\"{tokenized_datasets[train_ds_name].features}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always good to see what the tokenizer is doing to our data to ensure the special tokens are where we expect them to be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]Amrozi accused his brother, whom he called \" the witness \", of deliberately distorting his evidence.[SEP]Referring to him as only \" the witness \", Amrozi accused his brother of deliberately distorting his evidence.[SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer.decode(tokenized_datasets[train_ds_name][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use our `task_metrics` to compute the metrics for our model.  We'll return a dictionary of the metric name and value for each metric we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred, task_metrics):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    metrics_d = {}\n",
    "    for metric_func in task_metrics:\n",
    "        metric_name = metric_func.__name__\n",
    "        if metric_name in [\"pearsonr\", \"spearmanr\"]:\n",
    "            score = metric_func(labels, np.squeeze(predictions))\n",
    "        else:\n",
    "            score = metric_func(np.argmax(predictions, axis=-1), labels)\n",
    "\n",
    "        if isinstance(score, tuple):\n",
    "            metrics_d[metric_func.__name__] = score[0]\n",
    "        else:\n",
    "            metrics_d[metric_func.__name__] = score\n",
    "\n",
    "    return metrics_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "This is where the fun begins! Here we setup a few hyperparameters than have proven to work well for us in fine-tuning ModernBERT-base on GLUE tasks.  We'll also setup our model, data collator, and training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bsz, val_bsz = 32, 32\n",
    "lr = 8e-5\n",
    "betas = (0.9, 0.98)\n",
    "n_epochs = 2\n",
    "eps = 1e-6\n",
    "wd = 8e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When configuring `AutoModelForSequenceClassification`, two settings are critical to get things working with the HuggingFace `Trainer`. One is the `num_labels` we're expecting and the other is to set `compile=False` to avoid using the `torch.compile` function which is not supported in Transformers at the time of this writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "hf_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=n_labels, id2label=id2label, label2id=label2id, compile=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collation is easy for GLUE tasks as we can use the `DataCollatorWithPadding` class to pad our input_ids and attention_mask to the max length in the batch.\n",
    "\n",
    "**Note**: If you have installed Flash Attention, ModernBERT removes the padding internally, which makes it the fastest version. SPDA and Eager mode will be slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data_collator = DataCollatorWithPadding(tokenizer=hf_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the pieces in place, we can now setup our `TrainingArguments` and `Trainer` and get to training! Lots of customization is possible here and it is recommended to play with different schedulers and the hyperparameters we've started y'all off with above to improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"aai_ModernBERT_{task}_ft\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=train_bsz,\n",
    "    per_device_eval_batch_size=val_bsz,\n",
    "    num_train_epochs=n_epochs,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    optim=\"adamw_torch\",\n",
    "    adam_beta1=betas[0],\n",
    "    adam_beta2=betas[1],\n",
    "    adam_epsilon=eps,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    bf16=True,\n",
    "    bf16_full_eval=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define `TrainerCallback` so that we can capture all the training and evaluation logs and store them for later analysis. By default, the `Trainer` class will only keep the latest logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.training_history = {\"train\": [], \"eval\": []}\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            if \"loss\" in logs:  # Training logs\n",
    "                self.training_history[\"train\"].append(logs)\n",
    "            elif \"eval_loss\" in logs:  # Evaluation logs\n",
    "                self.training_history[\"eval\"].append(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.550361</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.817308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.414800</td>\n",
       "      <td>0.499648</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.822064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "      <th>eval_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6060</td>\n",
       "      <td>3.989608</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550361</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.817308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4148</td>\n",
       "      <td>5.573590</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.499648</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.822064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6060         3.989608              0.00004          1.0   0.550361   \n",
       "1      0.4148         5.573590              0.00000          2.0   0.499648   \n",
       "\n",
       "   eval_accuracy_score  eval_f1_score  \n",
       "0             0.720588       0.817308  \n",
       "1             0.754902       0.822064  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_mrpc_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_mrpc_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=hf_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[train_ds_name],\n",
    "    eval_dataset=tokenized_datasets[valid_ds_name],\n",
    "    processing_class=hf_tokenizer,\n",
    "    data_collator=hf_data_collator,\n",
    "    compute_metrics=partial(compute_metrics, task_metrics=task_metrics),\n",
    ")\n",
    "\n",
    "metrics_callback = MetricsCallback()\n",
    "trainer.add_callback(metrics_callback)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "train_history_df = pd.DataFrame(metrics_callback.training_history[\"train\"])\n",
    "train_history_df = train_history_df.add_prefix(\"train_\")\n",
    "eval_history_df = pd.DataFrame(metrics_callback.training_history[\"eval\"])\n",
    "train_res_df = pd.concat([train_history_df, eval_history_df], axis=1)\n",
    "\n",
    "args_df = pd.DataFrame([training_args.to_dict()])\n",
    "\n",
    "display(train_res_df)\n",
    "display(args_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "There'a number of options for inference within the HuggingFace ecosystem.  We'll go a bit old school here and just use the `forward` method of the model. We're not uploading this model to the hub, but this is an easy enough task for you to try out on your own should you like to share your ModernBERT finetune :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2422, -1.5234]], device='cuda:0')\n",
      "Prediction: NOT_EQUIVALENT\n"
     ]
    }
   ],
   "source": [
    "ex_1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "ex_2 = \"I love lamp!\"\n",
    "\n",
    "inf_inputs = hf_tokenizer(ex_1, ex_2, return_tensors=\"pt\")\n",
    "inf_inputs = inf_inputs.to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = hf_model(**inf_inputs).logits\n",
    "\n",
    "print(logits)\n",
    "print(f\"Prediction: {hf_model.config.id2label[logits.argmax().item()]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(things_to_delete: list | None = None):\n",
    "    if things_to_delete is not None:\n",
    "        for thing in things_to_delete:\n",
    "            if thing is not None:\n",
    "                del thing\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup(things_to_delete=[hf_model, trainer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train all the GLUE!\n",
    "\n",
    "If you got this far you're probably wondering why I put together that dictionary of GLUE tasks if all we're doing is finetuning a single model. The answer is basically that I'm a good and lazy programmer who would like to easily run hyperparameter sweeps and/or fine-tunes on all the GLUE tasks. So ... let's do that!\n",
    "\n",
    "We'll run with the training hyperparameters specified above and I leave it to the reader to improve the method below to be able to override these values should folks be looking for something to do :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_glue_task(\n",
    "    task: str, checkpoint: str = \"answerdotai/ModernBERT-base\", train_subset: int | None = None, do_cleanup: bool = True\n",
    "):  # 1. Load the task metadata\n",
    "    task_meta = glue_tasks[task]\n",
    "    train_ds_name = task_meta[\"dataset_names\"][\"train\"]\n",
    "    valid_ds_name = task_meta[\"dataset_names\"][\"valid\"]\n",
    "\n",
    "    task_inputs = task_meta[\"inputs\"]\n",
    "    n_labels = task_meta[\"n_labels\"]\n",
    "    task_metrics = task_meta[\"metric_funcs\"]\n",
    "\n",
    "    # 2. Load the dataset\n",
    "    raw_datasets = load_dataset(\"glue\", task.split(\"-\")[0] if \"-\" in task else task)\n",
    "    if train_subset is not None and len(raw_datasets[\"train\"]) > train_subset:\n",
    "        raw_datasets[\"train\"] = raw_datasets[\"train\"].shuffle(seed=42).select(range(train_subset))\n",
    "\n",
    "    id2label, label2id = get_label_maps(raw_datasets, train_ds_name)\n",
    "\n",
    "    # 3. Load the tokenizer\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    tokenized_datasets = raw_datasets.map(partial(preprocess_function, task_inputs=task_inputs), batched=True)\n",
    "\n",
    "    # 4. Define the compute metrics function\n",
    "    task_compute_metrics = partial(compute_metrics, task_metrics=task_metrics)\n",
    "\n",
    "    # 5. Load the model and data collator\n",
    "    model_additional_kwargs = {\"id2label\": id2label, \"label2id\": label2id} if id2label and label2id else {}\n",
    "    hf_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint, num_labels=n_labels, compile=False, **model_additional_kwargs\n",
    "    )\n",
    "\n",
    "    hf_data_collator = DataCollatorWithPadding(tokenizer=hf_tokenizer)\n",
    "\n",
    "    # 6. Define the training arguments and trainer\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"aai_ModernBERT_{task}_ft\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=train_bsz,\n",
    "        per_device_eval_batch_size=val_bsz,\n",
    "        num_train_epochs=n_epochs,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        optim=\"adamw_torch\",\n",
    "        adam_beta1=betas[0],\n",
    "        adam_beta2=betas[1],\n",
    "        adam_epsilon=eps,\n",
    "        logging_strategy=\"epoch\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        bf16=True,\n",
    "        bf16_full_eval=True,\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=hf_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[train_ds_name],\n",
    "        eval_dataset=tokenized_datasets[valid_ds_name],\n",
    "        processing_class=hf_tokenizer,\n",
    "        data_collator=hf_data_collator,\n",
    "        compute_metrics=task_compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Add callback to trainer\n",
    "    metrics_callback = MetricsCallback()\n",
    "    trainer.add_callback(metrics_callback)\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 7. Get the training results and hyperparameters\n",
    "    train_history_df = pd.DataFrame(metrics_callback.training_history[\"train\"])\n",
    "    train_history_df = train_history_df.add_prefix(\"train_\")\n",
    "    eval_history_df = pd.DataFrame(metrics_callback.training_history[\"eval\"])\n",
    "    train_res_df = pd.concat([train_history_df, eval_history_df], axis=1)\n",
    "\n",
    "    args_df = pd.DataFrame([training_args.to_dict()])\n",
    "\n",
    "    # 8. Cleanup (optional)\n",
    "    if do_cleanup:\n",
    "        cleanup(things_to_delete=[trainer, hf_model, hf_tokenizer, tokenized_datasets, raw_datasets])\n",
    "\n",
    "    return train_res_df, args_df, hf_model, hf_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helpful function encapsulates all the steps we've been through above and allows us to easily run a fine-tune on a single task. In addition to the HuggingFace objects, it returns the training results, training hyperparameters (all potentially helpful for performing sweeps and or documenting your results).\n",
    "\n",
    "Let's give it a go on both MRPC and CoLA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.563700</td>\n",
       "      <td>0.414041</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.872305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.326700</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.881295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "      <th>eval_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5637</td>\n",
       "      <td>3.246023</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.414041</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.872305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3267</td>\n",
       "      <td>5.002162</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.881295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.5637         3.246023              0.00004          1.0   0.414041   \n",
       "1      0.3267         5.002162              0.00000          2.0   0.371047   \n",
       "\n",
       "   eval_accuracy_score  eval_f1_score  \n",
       "0             0.811275       0.872305  \n",
       "1             0.838235       0.881295  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_mrpc_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_mrpc_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_res_df, args_df, hf_model, hf_tokenizer = finetune_glue_task(\n",
    "    \"mrpc\", checkpoint=\"answerdotai/ModernBERT-base\", do_cleanup=True\n",
    ")\n",
    "\n",
    "display(train_res_df)\n",
    "display(args_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='536' max='536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [536/536 01:14, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Corrcoef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.615100</td>\n",
       "      <td>0.525902</td>\n",
       "      <td>0.323947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.406600</td>\n",
       "      <td>0.441870</td>\n",
       "      <td>0.492141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_matthews_corrcoef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6151</td>\n",
       "      <td>8.100638</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.525902</td>\n",
       "      <td>0.323947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4066</td>\n",
       "      <td>11.885351</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.441870</td>\n",
       "      <td>0.492141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6151         8.100638              0.00004          1.0   0.525902   \n",
       "1      0.4066        11.885351              0.00000          2.0   0.441870   \n",
       "\n",
       "   eval_matthews_corrcoef  \n",
       "0                0.323947  \n",
       "1                0.492141  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_cola_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_cola_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_res_df, args_df, hf_model, hf_tokenizer = finetune_glue_task(\n",
    "    \"cola\", checkpoint=\"answerdotai/ModernBERT-base\", do_cleanup=True\n",
    ")\n",
    "\n",
    "display(train_res_df)\n",
    "display(args_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Send it!**\n",
    "\n",
    "Grab yourself a good cup of coffee, take your pups out for a walk, or whatever as your GPU purrs along while finetuning all things GLUE!\n",
    "\n",
    "Note the `train_subset` parameter which allows us to train on a subset of the dataset. This is helpful for quickly testing the model on a small dataset to make sure all the bits work as expected.  Feel free to set it to `None` for a full send!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning cola -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Corrcoef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.607800</td>\n",
       "      <td>0.604273</td>\n",
       "      <td>0.043760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.595953</td>\n",
       "      <td>0.228080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_matthews_corrcoef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6078</td>\n",
       "      <td>40.798195</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604273</td>\n",
       "      <td>0.04376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4050</td>\n",
       "      <td>12.892710</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.595953</td>\n",
       "      <td>0.22808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6078        40.798195              0.00004          1.0   0.604273   \n",
       "1      0.4050        12.892710              0.00000          2.0   0.595953   \n",
       "\n",
       "   eval_matthews_corrcoef  \n",
       "0                 0.04376  \n",
       "1                 0.22808  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_cola_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_cola_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning sst2 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.569200</td>\n",
       "      <td>0.393088</td>\n",
       "      <td>0.834862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.313808</td>\n",
       "      <td>0.870413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5692</td>\n",
       "      <td>13.669675</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.393088</td>\n",
       "      <td>0.834862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2314</td>\n",
       "      <td>5.367749</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.313808</td>\n",
       "      <td>0.870413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.5692        13.669675              0.00004          1.0   0.393088   \n",
       "1      0.2314         5.367749              0.00000          2.0   0.313808   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.834862  \n",
       "1             0.870413  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_sst2_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_sst2_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning mrpc -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.637600</td>\n",
       "      <td>0.508369</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.831386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.446494</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.851789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "      <th>eval_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6376</td>\n",
       "      <td>13.762523</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508369</td>\n",
       "      <td>0.752451</td>\n",
       "      <td>0.831386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4279</td>\n",
       "      <td>10.919047</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.446494</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.851789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6376        13.762523              0.00004          1.0   0.508369   \n",
       "1      0.4279        10.919047              0.00000          2.0   0.446494   \n",
       "\n",
       "   eval_accuracy_score  eval_f1_score  \n",
       "0             0.752451       0.831386  \n",
       "1             0.786765       0.851789  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_mrpc_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_mrpc_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning stsb -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearsonr</th>\n",
       "      <th>Spearmanr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.441400</td>\n",
       "      <td>1.323127</td>\n",
       "      <td>0.735928</td>\n",
       "      <td>0.744267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.743600</td>\n",
       "      <td>0.831915</td>\n",
       "      <td>0.802678</td>\n",
       "      <td>0.804716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_pearsonr</th>\n",
       "      <th>eval_spearmanr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4414</td>\n",
       "      <td>43.095963</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.323127</td>\n",
       "      <td>0.735928</td>\n",
       "      <td>0.744267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7436</td>\n",
       "      <td>22.308477</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.831915</td>\n",
       "      <td>0.802678</td>\n",
       "      <td>0.804716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      2.4414        43.095963              0.00004          1.0   1.323127   \n",
       "1      0.7436        22.308477              0.00000          2.0   0.831915   \n",
       "\n",
       "   eval_pearsonr  eval_spearmanr  \n",
       "0       0.735928        0.744267  \n",
       "1       0.802678        0.804716  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_stsb_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_stsb_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning qqp -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/390965 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 390965/390965 [00:33<00:00, 11761.24 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 01:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.607400</td>\n",
       "      <td>0.499629</td>\n",
       "      <td>0.621215</td>\n",
       "      <td>0.728321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.732278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1_score</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6074</td>\n",
       "      <td>8.23535</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499629</td>\n",
       "      <td>0.621215</td>\n",
       "      <td>0.728321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4850</td>\n",
       "      <td>36.08305</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>0.615188</td>\n",
       "      <td>0.732278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6074          8.23535              0.00004          1.0   0.499629   \n",
       "1      0.4850         36.08305              0.00000          2.0   0.524866   \n",
       "\n",
       "   eval_f1_score  eval_accuracy_score  \n",
       "0       0.621215             0.728321  \n",
       "1       0.615188             0.732278  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_qqp_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              output_dir  overwrite_output_dir  do_train  do_eval  do_predict  \\\n",
       "0  aai_modernbert_qqp_ft                 False     False     True       False   \n",
       "\n",
       "  eval_strategy  prediction_loss_only  per_device_train_batch_size  \\\n",
       "0         epoch                 False                           32   \n",
       "\n",
       "   per_device_eval_batch_size per_gpu_train_batch_size  ... split_batches  \\\n",
       "0                          32                     None  ...          None   \n",
       "\n",
       "   include_tokens_per_second include_num_input_tokens_seen  \\\n",
       "0                      False                         False   \n",
       "\n",
       "   neftune_noise_alpha optim_target_modules  batch_eval_metrics  \\\n",
       "0                 None                 None               False   \n",
       "\n",
       "   eval_on_start  use_liger_kernel  eval_use_gather_object  \\\n",
       "0          False             False                   False   \n",
       "\n",
       "   average_tokens_across_devices  \n",
       "0                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning mnli-matched -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/9847 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9847/9847 [00:01<00:00, 9226.73 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.147100</td>\n",
       "      <td>1.068802</td>\n",
       "      <td>0.406215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.935800</td>\n",
       "      <td>1.027365</td>\n",
       "      <td>0.471014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1471</td>\n",
       "      <td>7.386725</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.068802</td>\n",
       "      <td>0.406215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9358</td>\n",
       "      <td>13.833081</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.027365</td>\n",
       "      <td>0.471014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      1.1471         7.386725              0.00004          1.0   1.068802   \n",
       "1      0.9358        13.833081              0.00000          2.0   1.027365   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.406215  \n",
       "1             0.471014  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_mnli-matched_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_mnli-matched_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning mnli-mismatched -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.147100</td>\n",
       "      <td>1.055565</td>\n",
       "      <td>0.423922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.935500</td>\n",
       "      <td>1.011183</td>\n",
       "      <td>0.494304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1471</td>\n",
       "      <td>7.386725</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.055565</td>\n",
       "      <td>0.423922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9355</td>\n",
       "      <td>12.523493</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.011183</td>\n",
       "      <td>0.494304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      1.1471         7.386725              0.00004          1.0   1.055565   \n",
       "1      0.9355        12.523493              0.00000          2.0   1.011183   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.423922  \n",
       "1             0.494304  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_mnli-mismatched_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_mnli-mismatched_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning qnli -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/5463 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5463/5463 [00:00<00:00, 7358.18 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>0.526290</td>\n",
       "      <td>0.742998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>0.603152</td>\n",
       "      <td>0.731832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6957</td>\n",
       "      <td>69.748146</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526290</td>\n",
       "      <td>0.742998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4177</td>\n",
       "      <td>16.136906</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.603152</td>\n",
       "      <td>0.731832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6957        69.748146              0.00004          1.0   0.526290   \n",
       "1      0.4177        16.136906              0.00000          2.0   0.603152   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.742998  \n",
       "1             0.731832  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_qnli_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_qnli_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning rte -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:00<00:00, 5602.09 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:32, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.755100</td>\n",
       "      <td>0.707934</td>\n",
       "      <td>0.509025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.690976</td>\n",
       "      <td>0.498195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7551</td>\n",
       "      <td>5.044735</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707934</td>\n",
       "      <td>0.509025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6556</td>\n",
       "      <td>6.338690</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.690976</td>\n",
       "      <td>0.498195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.7551         5.044735              0.00004          1.0   0.707934   \n",
       "1      0.6556         6.338690              0.00000          2.0   0.690976   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.509025  \n",
       "1             0.498195  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_rte_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              output_dir  overwrite_output_dir  do_train  do_eval  do_predict  \\\n",
       "0  aai_modernbert_rte_ft                 False     False     True       False   \n",
       "\n",
       "  eval_strategy  prediction_loss_only  per_device_train_batch_size  \\\n",
       "0         epoch                 False                           32   \n",
       "\n",
       "   per_device_eval_batch_size per_gpu_train_batch_size  ... split_batches  \\\n",
       "0                          32                     None  ...          None   \n",
       "\n",
       "   include_tokens_per_second include_num_input_tokens_seen  \\\n",
       "0                      False                         False   \n",
       "\n",
       "   neftune_noise_alpha optim_target_modules  batch_eval_metrics  \\\n",
       "0                 None                 None               False   \n",
       "\n",
       "   eval_on_start  use_liger_kernel  eval_use_gather_object  \\\n",
       "0          False             False                   False   \n",
       "\n",
       "   average_tokens_across_devices  \n",
       "0                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning wnli -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/146 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 146/146 [00:00<00:00, 5646.34 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.789800</td>\n",
       "      <td>0.709700</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>0.691901</td>\n",
       "      <td>0.563380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7898</td>\n",
       "      <td>6.372931</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.709700</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7183</td>\n",
       "      <td>3.087399</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.691901</td>\n",
       "      <td>0.56338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.7898         6.372931              0.00004          1.0   0.709700   \n",
       "1      0.7183         3.087399              0.00000          2.0   0.691901   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0              0.56338  \n",
       "1              0.56338  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>split_batches</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_modernbert_wnli_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_modernbert_wnli_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... split_batches  include_tokens_per_second  \\\n",
       "0                     None  ...          None                      False   \n",
       "\n",
       "  include_num_input_tokens_seen  neftune_noise_alpha optim_target_modules  \\\n",
       "0                         False                 None                 None   \n",
       "\n",
       "   batch_eval_metrics  eval_on_start  use_liger_kernel  \\\n",
       "0               False          False             False   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for task in glue_tasks.keys():\n",
    "    print(f\"----- Finetuning {task} -----\")\n",
    "    train_res_df, args_df, hf_model, hf_tokenizer = finetune_glue_task(\n",
    "        task, checkpoint=\"answerdotai/ModernBERT-base\", train_subset=1_000, do_cleanup=True\n",
    "    )\n",
    "\n",
    "    print(\":: Results ::\")\n",
    "    display(train_res_df)\n",
    "    display(args_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "With ModernBERT encoders are back baby!  We've seen that ModernBERT-base can compete with the best of them on GLUE tasks and with a little more tuning, we'll see that ModernBERT-large can do even better.  I'm excited to see what the community will do with this model and I'm looking forward to seeing what you all build with it! We'll be exploring more of the capabilities of ModernBERT in future tutorials.\n",
    "\n",
    "Until next time, happy coding!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
